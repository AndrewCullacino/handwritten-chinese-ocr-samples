{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a65b317",
   "metadata": {},
   "source": [
    "# Debug: CUDA Out of Memory Fix\n",
    "\n",
    "## Problem\n",
    "The training crashes with `torch.OutOfMemoryError` because:\n",
    "1. **Variable-width images**: Text line images have widths up to 2475+ pixels\n",
    "2. **Batch padding**: `AlignCollate` pads ALL images in a batch to the maximum width\n",
    "3. **Memory explosion**: batch_size=48 × 128 height × 2475 width = **huge memory usage**\n",
    "\n",
    "## Solutions\n",
    "\n",
    "### Solution 1: Limit Maximum Image Width (Recommended)\n",
    "Truncate very long images to a maximum width (e.g., 1600 pixels). This loses some text but prevents OOM.\n",
    "\n",
    "### Solution 2: Dynamic Batch Sizing\n",
    "Reduce batch size when images are very wide.\n",
    "\n",
    "### Solution 3: Gradient Accumulation\n",
    "Use smaller actual batch size but accumulate gradients to simulate larger batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9afd44",
   "metadata": {},
   "source": [
    "## Fix 1: Update `utils/dataset.py` - Add Maximum Width Limit\n",
    "\n",
    "This is the **primary fix**. We modify `AlignCollate` to cap the maximum width and add width limiting in `pil_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to make in utils/dataset.py\n",
    "\n",
    "# 1. Update AlignCollate class to accept max_width parameter:\n",
    "\"\"\"\n",
    "class AlignCollate(object):\n",
    "    def __init__(self, imgH=48, PAD='ZerosPAD', max_width=1600):\n",
    "        self.imgH = imgH\n",
    "        self.PAD = PAD\n",
    "        self.max_width = max_width  # Maximum width to prevent OOM\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = filter(lambda x: x is not None, batch)\n",
    "        images, labels = zip(*batch)\n",
    "\n",
    "        maxW = 0\n",
    "        for image in images:\n",
    "            h, w, c = image.shape\n",
    "            if w > maxW:\n",
    "                maxW = w\n",
    "        \n",
    "        # Cap maximum width to prevent OOM errors\n",
    "        maxW = min(maxW, self.max_width)\n",
    "\n",
    "        if self.PAD == 'ZerosPAD':\n",
    "            trans = ZerosPAD((1, self.imgH, maxW))\n",
    "        elif self.PAD == 'NormalizePAD':\n",
    "            trans = NormalizePAD((1, self.imgH, maxW))\n",
    "        else:\n",
    "            raise ValueError(\"not expected padding.\")\n",
    "\n",
    "        padded_images = []\n",
    "        for image in images:\n",
    "            h, w, c = image.shape\n",
    "            # Truncate image if wider than max_width\n",
    "            if w > maxW:\n",
    "                image = image[:, :maxW, :]\n",
    "            padded_images.append(trans(image))\n",
    "\n",
    "        image_tensors = torch.cat([t.unsqueeze(0) for t in padded_images], 0)\n",
    "\n",
    "        return image_tensors, labels\n",
    "\"\"\"\n",
    "print(\"AlignCollate fix ready - adds max_width parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0acb9",
   "metadata": {},
   "source": [
    "## Fix 2: Update `main.py` - Use New API and Lower Batch Size\n",
    "\n",
    "Two issues to fix:\n",
    "1. **Deprecated TF32 API**: PyTorch 2.9+ warns about old `allow_tf32` settings\n",
    "2. **Deprecated AMP API**: `torch.cuda.amp.GradScaler` and `autocast` are deprecated\n",
    "3. **Batch size**: Reduce from 48 to 32 for safety with variable-width images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to make in main.py\n",
    "\n",
    "# 1. Update setup_a100_optimizations() to use new TF32 API:\n",
    "\"\"\"\n",
    "def setup_a100_optimizations():\n",
    "    if torch.cuda.is_available():\n",
    "        # New TF32 API (PyTorch 2.9+)\n",
    "        try:\n",
    "            # Try new API first\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        # Enable cuDNN benchmarking\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        ...\n",
    "\"\"\"\n",
    "\n",
    "# 2. Update GradScaler to new API (line ~247):\n",
    "# OLD: scaler = GradScaler()\n",
    "# NEW: scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# 3. Update autocast to new API (line ~382):\n",
    "# OLD: with autocast():\n",
    "# NEW: with torch.amp.autocast('cuda'):\n",
    "\n",
    "# 4. Update imports at top:\n",
    "# OLD: from torch.cuda.amp import autocast, GradScaler\n",
    "# NEW: (remove this line, use torch.amp directly)\n",
    "\n",
    "print(\"main.py fixes ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e59cb3",
   "metadata": {},
   "source": [
    "## Recommended Settings (Updated after 2nd OOM)\n",
    "\n",
    "The model is large (~38M parameters). More conservative settings needed:\n",
    "\n",
    "| GPU | VRAM | max_width | Batch Size |\n",
    "|-----|------|-----------|------------|\n",
    "| A100 40GB | 40 GB | 1200 | **16** |\n",
    "| A100 80GB | 80 GB | 1600 | 32-48 |\n",
    "| V100 | 16-32 GB | 1000 | 8-12 |\n",
    "| T4 | 16 GB | 1000 | 4-8 |\n",
    "\n",
    "**Key insight**: Even with max_width=1600, the feature maps in deeper layers consume significant memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66d2d2",
   "metadata": {},
   "source": [
    "## Summary of Final Fix\n",
    "\n",
    "**Root cause**: The model has ~38M parameters with deep ResNet + SE blocks. Even with truncated images, batch_size=32 exceeded 40GB A100 memory.\n",
    "\n",
    "### Final Settings Applied:\n",
    "- **max_width**: 1200 (reduced from 1600)\n",
    "- **batch_size**: 16 for A100 40GB (reduced from 32)\n",
    "\n",
    "### Files Modified:\n",
    "1. `main.py` - Changed `max_width = 1200`\n",
    "2. `colab_train.ipynb` - Updated batch sizes (A100: 16, V100: 12, T4: 8)\n",
    "\n",
    "### To Resume Training in Colab:\n",
    "```bash\n",
    "!git pull origin main\n",
    "!python main.py -m hctr -d data/hwdb2.0 -b 16 -ep 50 -pf 100 -vf 5000 -j 4\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ad179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Colab, run:\n",
    "# !git pull origin main\n",
    "# !python main.py -m hctr -d data/hwdb2.0 -b 16 -ep 50 -pf 100 -vf 5000 -j 4\n",
    "\n",
    "# If still OOM, try batch_size=12 or 8:\n",
    "# !python main.py -m hctr -d data/hwdb2.0 -b 12 -ep 50 -pf 100 -vf 5000 -j 4\n",
    "\n",
    "print(\"Use batch_size=16 for A100 40GB with max_width=1200\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
