{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a65b317",
   "metadata": {},
   "source": [
    "# Debug: CUDA Out of Memory Fix\n",
    "\n",
    "## Problem\n",
    "The training crashes with `torch.OutOfMemoryError` because:\n",
    "1. **Variable-width images**: Text line images have widths up to 2475+ pixels\n",
    "2. **Batch padding**: `AlignCollate` pads ALL images in a batch to the maximum width\n",
    "3. **Memory explosion**: batch_size=48 × 128 height × 2475 width = **huge memory usage**\n",
    "\n",
    "## Solutions\n",
    "\n",
    "### Solution 1: Limit Maximum Image Width (Recommended)\n",
    "Truncate very long images to a maximum width (e.g., 1600 pixels). This loses some text but prevents OOM.\n",
    "\n",
    "### Solution 2: Dynamic Batch Sizing\n",
    "Reduce batch size when images are very wide.\n",
    "\n",
    "### Solution 3: Gradient Accumulation\n",
    "Use smaller actual batch size but accumulate gradients to simulate larger batches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9afd44",
   "metadata": {},
   "source": [
    "## Fix 1: Update `utils/dataset.py` - Add Maximum Width Limit\n",
    "\n",
    "This is the **primary fix**. We modify `AlignCollate` to cap the maximum width and add width limiting in `pil_loader`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc683e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to make in utils/dataset.py\n",
    "\n",
    "# 1. Update AlignCollate class to accept max_width parameter:\n",
    "\"\"\"\n",
    "class AlignCollate(object):\n",
    "    def __init__(self, imgH=48, PAD='ZerosPAD', max_width=1600):\n",
    "        self.imgH = imgH\n",
    "        self.PAD = PAD\n",
    "        self.max_width = max_width  # Maximum width to prevent OOM\n",
    "\n",
    "    def __call__(self, batch):\n",
    "        batch = filter(lambda x: x is not None, batch)\n",
    "        images, labels = zip(*batch)\n",
    "\n",
    "        maxW = 0\n",
    "        for image in images:\n",
    "            h, w, c = image.shape\n",
    "            if w > maxW:\n",
    "                maxW = w\n",
    "        \n",
    "        # Cap maximum width to prevent OOM errors\n",
    "        maxW = min(maxW, self.max_width)\n",
    "\n",
    "        if self.PAD == 'ZerosPAD':\n",
    "            trans = ZerosPAD((1, self.imgH, maxW))\n",
    "        elif self.PAD == 'NormalizePAD':\n",
    "            trans = NormalizePAD((1, self.imgH, maxW))\n",
    "        else:\n",
    "            raise ValueError(\"not expected padding.\")\n",
    "\n",
    "        padded_images = []\n",
    "        for image in images:\n",
    "            h, w, c = image.shape\n",
    "            # Truncate image if wider than max_width\n",
    "            if w > maxW:\n",
    "                image = image[:, :maxW, :]\n",
    "            padded_images.append(trans(image))\n",
    "\n",
    "        image_tensors = torch.cat([t.unsqueeze(0) for t in padded_images], 0)\n",
    "\n",
    "        return image_tensors, labels\n",
    "\"\"\"\n",
    "print(\"AlignCollate fix ready - adds max_width parameter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e0acb9",
   "metadata": {},
   "source": [
    "## Fix 2: Update `main.py` - Use New API and Lower Batch Size\n",
    "\n",
    "Two issues to fix:\n",
    "1. **Deprecated TF32 API**: PyTorch 2.9+ warns about old `allow_tf32` settings\n",
    "2. **Deprecated AMP API**: `torch.cuda.amp.GradScaler` and `autocast` are deprecated\n",
    "3. **Batch size**: Reduce from 48 to 32 for safety with variable-width images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccabdae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changes to make in main.py\n",
    "\n",
    "# 1. Update setup_a100_optimizations() to use new TF32 API:\n",
    "\"\"\"\n",
    "def setup_a100_optimizations():\n",
    "    if torch.cuda.is_available():\n",
    "        # New TF32 API (PyTorch 2.9+)\n",
    "        try:\n",
    "            # Try new API first\n",
    "            torch.backends.cuda.matmul.allow_tf32 = True\n",
    "            torch.backends.cudnn.allow_tf32 = True\n",
    "        except AttributeError:\n",
    "            pass\n",
    "        \n",
    "        # Enable cuDNN benchmarking\n",
    "        torch.backends.cudnn.benchmark = True\n",
    "        ...\n",
    "\"\"\"\n",
    "\n",
    "# 2. Update GradScaler to new API (line ~247):\n",
    "# OLD: scaler = GradScaler()\n",
    "# NEW: scaler = torch.amp.GradScaler('cuda')\n",
    "\n",
    "# 3. Update autocast to new API (line ~382):\n",
    "# OLD: with autocast():\n",
    "# NEW: with torch.amp.autocast('cuda'):\n",
    "\n",
    "# 4. Update imports at top:\n",
    "# OLD: from torch.cuda.amp import autocast, GradScaler\n",
    "# NEW: (remove this line, use torch.amp directly)\n",
    "\n",
    "print(\"main.py fixes ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e59cb3",
   "metadata": {},
   "source": [
    "## Recommended Batch Sizes with max_width=1600\n",
    "\n",
    "| GPU | VRAM | Recommended Batch Size |\n",
    "|-----|------|----------------------|\n",
    "| A100 40GB | 40 GB | 32-40 |\n",
    "| A100 80GB | 80 GB | 48-64 |\n",
    "| V100 | 16-32 GB | 16-24 |\n",
    "| T4 | 16 GB | 8-12 |\n",
    "\n",
    "With `max_width=1600`, batch_size=32 should be safe on A100 40GB."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d66d2d2",
   "metadata": {},
   "source": [
    "## Summary of Changes Applied\n",
    "\n",
    "The following files have been modified to fix the OOM error:\n",
    "\n",
    "### 1. `utils/dataset.py`\n",
    "- Added `max_width` parameter to `AlignCollate` class (default: 1600)\n",
    "- Images wider than `max_width` are truncated\n",
    "- Warning printed when truncation occurs\n",
    "\n",
    "### 2. `main.py`\n",
    "- Updated to use new PyTorch 2.0+ AMP API (`torch.amp.autocast('cuda')` and `torch.amp.GradScaler('cuda')`)\n",
    "- Added `max_width=1600` to all `AlignCollate` calls\n",
    "- Fixed deprecated TF32 warnings\n",
    "\n",
    "### 3. `colab_train.ipynb`\n",
    "- Reduced A100 batch size from 48 to 32 (safer with variable-width images)\n",
    "- Reduced V100 batch size from 24 to 20\n",
    "- Added documentation about max_width enforcement\n",
    "\n",
    "## To Re-run Training\n",
    "\n",
    "Simply run the training command again. The OOM should be fixed now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215ad179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this command in Colab after pulling the updated code:\n",
    "# !git pull origin main\n",
    "\n",
    "# Then run training:\n",
    "# !python main.py -m hctr -d data/hwdb2.0 -b 32 -ep 50 -pf 100 -vf 5000 -j 4\n",
    "\n",
    "print(\"Training command ready. Use batch_size=32 for A100 40GB.\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
